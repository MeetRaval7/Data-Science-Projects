{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset,mnist_info=tfds.load(name='mnist',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train,mnist_test=mnist_dataset['train'],mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_validation_samples=0.1*mnist_info.splits['train'].num_examples\n",
    "no_of_validation_samples=tf.cast(no_of_validation_samples,tf.int64)\n",
    "\n",
    "no_of_test_samples=mnist_info.splits['test'].num_examples\n",
    "no_of_test_samples=tf.cast(no_of_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size=70000\n",
    "batch_size=128\n",
    "max_epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label):\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image/=255.\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_and_validation_data=mnist_train.map(scale)\n",
    "scaled_test_data=mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffled_train_and_validation_data=scaled_train_and_validation_data.shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=suffled_train_and_validation_data.take(no_of_validation_samples)\n",
    "train_data=suffled_train_and_validation_data.skip(no_of_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.batch(batch_size)\n",
    "validation_data=validation_data.batch(no_of_validation_samples)\n",
    "test_data=scaled_test_data.batch(no_of_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_Filter_Size=hp.HParam('filter_size',hp.Discrete([3,5,7]))\n",
    "HP_optimizer=hp.HParam('optimizer',hp.Discrete(['adam','sgd']))\n",
    "\n",
    "METRIC_ACCURACY='accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_Filter_Size,HP_optimizer],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY,display_name='Accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(50,hparams[HP_Filter_Size],activation='relu',input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(50,hparams[HP_Filter_Size],activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10)])\n",
    "    loss_rn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits='softmax')\n",
    "    model.compile(optimizer=hparams[HP_optimizer],loss=loss_rn,metrics=['accuracy'])\n",
    "    early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='auto',min_delta=0,verbose=0,patience=2,restore_best_weights=True)\n",
    "    model.fit(train_data,epochs=max_epoch,callbacks=[early_stopping],validation_data=validation_data,verbose=2)\n",
    "    _,accuracy=model.evaluate(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir,hparams):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy=train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-0\n",
      "{'filter_size': 3, 'optimizer': 'adam'}\n",
      "Epoch 1/20\n",
      "422/422 - 79s - loss: 0.2924 - accuracy: 0.9136 - val_loss: 0.0886 - val_accuracy: 0.9737\n",
      "Epoch 2/20\n",
      "422/422 - 78s - loss: 0.0792 - accuracy: 0.9763 - val_loss: 0.0592 - val_accuracy: 0.9827\n",
      "Epoch 3/20\n",
      "422/422 - 73s - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0443 - val_accuracy: 0.9863\n",
      "Epoch 4/20\n",
      "422/422 - 74s - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.0378 - val_accuracy: 0.9877\n",
      "Epoch 5/20\n",
      "422/422 - 78s - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0454 - val_accuracy: 0.9873\n",
      "Epoch 6/20\n",
      "422/422 - 83s - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0230 - val_accuracy: 0.9925\n",
      "Epoch 7/20\n",
      "422/422 - 85s - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0226 - val_accuracy: 0.9933\n",
      "Epoch 8/20\n",
      "422/422 - 87s - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0301 - val_accuracy: 0.9913\n",
      "Epoch 9/20\n",
      "422/422 - 73s - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0191 - val_accuracy: 0.9953\n",
      "Epoch 10/20\n",
      "422/422 - 77s - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0123 - val_accuracy: 0.9968\n",
      "Epoch 11/20\n",
      "422/422 - 74s - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 12/20\n",
      "422/422 - 78s - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0112 - val_accuracy: 0.9970\n",
      "Epoch 13/20\n",
      "422/422 - 85s - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
      "Epoch 14/20\n",
      "422/422 - 73s - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0137 - val_accuracy: 0.9952\n",
      "      1/Unknown - 12s 12s/step - loss: 0.0318 - accuracy: 0.9900---Starting trial: run-1\n",
      "{'filter_size': 3, 'optimizer': 'sgd'}\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "session_num=0\n",
    "for filter_size in HP_Filter_Size.domain.values:\n",
    "    for optimizer in HP_optimizer.domain.values:\n",
    "        hparams={\n",
    "            HP_Filter_Size:filter_size,\n",
    "            HP_optimizer:optimizer\n",
    "        }\n",
    "        run_name='run-%d' % session_num\n",
    "        print('---Starting trial: %s' % run_name)\n",
    "        print({h.name:hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/'+run_name,hparams)\n",
    "        \n",
    "        session_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.503766). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.503766). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 - 73s - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0192 - val_accuracy: 0.9930\n",
      "Epoch 2/20\n",
      "422/422 - 70s - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0133 - val_accuracy: 0.9955\n",
      "Epoch 3/20\n",
      "422/422 - 69s - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0129 - val_accuracy: 0.9958\n",
      "Epoch 4/20\n",
      "422/422 - 70s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 5/20\n",
      "422/422 - 74s - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0106 - val_accuracy: 0.9965\n",
      "Epoch 6/20\n",
      "422/422 - 75s - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
      "Epoch 7/20\n",
      "422/422 - 76s - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0064 - val_accuracy: 0.9980\n",
      "Epoch 8/20\n",
      "422/422 - 83s - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
      "Epoch 9/20\n",
      "422/422 - 89s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 10/20\n",
      "422/422 - 89s - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 11/20\n",
      "422/422 - 87s - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f00b5e0b08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3184), started 0:00:21 ago. (Use '!kill 3184' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4459ed6933ccd22d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4459ed6933ccd22d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'logs/hparam_tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 42s 42s/step - loss: 0.0392 - accuracy: 0.9906"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
